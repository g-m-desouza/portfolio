{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41d66470",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pymongo\n",
    "from tkinter import *\n",
    "from tkinter import filedialog as fd\n",
    "from tkinter.messagebox import showinfo\n",
    "from pymongo.errors import BulkWriteError\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import datetime\n",
    "import os\n",
    "from bson.json_util import loads,dumps\n",
    "import bson.json_util as js_utils\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg, NavigationToolbar2Tk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41da6bf5",
   "metadata": {},
   "source": [
    "#### classes for parsing and mongodb CRUD operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4e49491",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the client wants UK airportdata only so non-UK airports is excluded    \n",
    "\n",
    "class Validation(object):\n",
    "    def __init__(self,csvFile):\n",
    "        self.csvFile=csvFile\n",
    "        \n",
    "    ###validation check to ensure the csv data is coming from 1 of 3: airport-frequencies,airports or runways\n",
    "    \n",
    "    def validation_check(self,criteria):\n",
    "       \n",
    "        checkList1=[]\n",
    "        control=0\n",
    "        for line in self.csvFile:\n",
    "            while control < 1:\n",
    "                checkList1.append(line.keys())\n",
    "                control+=1\n",
    "        \n",
    "        checkList2=[]\n",
    "        for item in checkList1[0]:\n",
    "            checkList2.append(item)\n",
    "\n",
    "        valnum=0\n",
    "        for label in criteria:\n",
    "            if label in checkList2:\n",
    "                valnum+=1\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        if valnum == 18 or valnum ==20 or valnum == 6:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "\n",
    "    \n",
    "     \n",
    "    ###where the ids in the id's field in the csv is used as the id in mongo, so that mongo doesn't autogen\n",
    "    ###ids. This prevents duplication of documents\n",
    "class Mongo_prep(object):\n",
    "    def __init__(self,csvFile=None):\n",
    "        self.csvFile=csvFile\n",
    "       \n",
    "        \n",
    "    def iD(self):\n",
    "        listcon=[]\n",
    "        for line in self.csvFile:\n",
    "            line['_id']=line.pop('id')\n",
    "            listcon.append(line)\n",
    "        return listcon\n",
    "    \n",
    "    def surrogateKey(self,df):\n",
    "        df.rename(columns = {'_id':'id'}, inplace = True)\n",
    "        df['PlaceHolderID'] =df['frequency_mhz']\n",
    "        df['PlaceHolderID'] = df['PlaceHolderID'].replace(np.NaN,\"0\")\n",
    "        df['_id']=(\"ICAO#\"+df[\"ident\"])+(\"Freq\"+df[\"PlaceHolderID\"])\n",
    "        df.drop(columns='PlaceHolderID',inplace=True)\n",
    "    \n",
    "        return df\n",
    "\n",
    "               \n",
    " #adding columns needed, and included small_airport,medium_airport,large_airport\n",
    "   \n",
    "class MongoDB_controls(object):\n",
    "    def __init__(self,client):\n",
    "        self.client = pymongo.MongoClient(client)\n",
    "            \n",
    "#     def mongo_start(self):\n",
    "#         client = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "#         return client\n",
    "        \n",
    "    def mongo_db(self,db):\n",
    "        db=self.client[db]\n",
    "        return db\n",
    "        \n",
    "    def mongo_collection(self,db,collection):\n",
    "        collection=db[collection]\n",
    "        return  collection\n",
    " \n",
    " #inserting functions          \n",
    "    def mongo_insertMany(self,collection,file):\n",
    "        collection.insert_many(file)\n",
    "      \n",
    "  #Needs testing    \n",
    "    def mongo_insertOne(self,collection,file):\n",
    "        collection.insert_one(file)\n",
    "        \n",
    "    def mongo_call(self):\n",
    "        return self.client.list_database_names()\n",
    "        \n",
    "    def mongo_find(self,collection,rows=\" \"):\n",
    "        call=[]\n",
    "        if rows==\" \":\n",
    "            result = collection.find({})\n",
    "            for r in result:\n",
    "                call.append(r)\n",
    "            return call\n",
    "        else:\n",
    "            result = collection.find(rows)\n",
    "            for r in result:\n",
    "                call.append(r)\n",
    "            return call\n",
    "        \n",
    "   #delete block needs testing\n",
    "    def mongo_deleteOne(self,collection,del_record):\n",
    "        collection.delete_one(del_record)\n",
    "            \n",
    "    def mongo_deleteMany(self,collection,del_records):\n",
    "        collection.delete_many(del_records)\n",
    "         \n",
    "    def mongo_DeleteAll(self,collection):\n",
    "            collection.delete_many({})\n",
    "        \n",
    "    #update block\n",
    "    def mongo_updateOne(self,collection,iD,data):\n",
    "        collection.update_one({'id':iD},{\"$set\":data})\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6a879e",
   "metadata": {},
   "source": [
    "#### Cleaning dataset using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcaba19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##this class is there to prep the airport data\n",
    "class Pandas_airport(object):\n",
    "    def __init__(self,df):\n",
    "        self.df=df\n",
    "        \n",
    "    def dropTypeClose(self):\n",
    "        df=self.df\n",
    "        df.drop(df.index[df['type']=='closed'],inplace=True)\n",
    "        df.reset_index(inplace=True)\n",
    "        \n",
    "     #creating blank columns equal to the number of unique values found under type   \n",
    "    def airportTypeColumns(self):\n",
    "        df=self.df\n",
    "        df[df.type.unique()]=\"\"\n",
    "        for uniquedf in df.type.unique():\n",
    "            df[uniquedf]=df['type']\n",
    "\n",
    "\n",
    "    \n",
    "    def marker(self,aiportType):\n",
    "        df = self.df\n",
    "        removeVal=[]\n",
    "        keepVal=[]\n",
    "        for unique in df.type.unique():\n",
    "            if unique == aiportType:\n",
    "                keepVal.append(unique)\n",
    "            else:\n",
    "                removeVal.append(unique)\n",
    "        \n",
    "        ### the following code is used to place a place holder \"np.NaN\" needed to copy across freq data\n",
    "        \n",
    "        df[aiportType] = df[aiportType].replace(removeVal,'')\n",
    "        df[aiportType] = df[aiportType].replace(keepVal,np.NaN)\n",
    "        \n",
    "    ## this block keeps GB airports columns plus small_airport, medium_airport and large_airport types & columns and drops the \n",
    "    ## rest. Filtered on iso_country as these codes are unique to each country\n",
    "    \n",
    "    def sizeNGB_sec(self):\n",
    "        df = self.df\n",
    "        df.drop(df.index[df['iso_country']!='GB'],inplace=True)\n",
    "        df=df.filter(items=[\"_id\",\"ident\",\"type\",\"name\",\"latitude_deg\",\"longitude_deg\",\n",
    "                         \"elevation_ft\",\"continent\",\"iso_country\" ,\"iso_region\",\n",
    "                         \"municipality\",\"scheduled_service\",\"iata_code\",\"local_code\",\n",
    "                          \"home_link\",\"wikipedia_link\",\"keywords\",\n",
    "                         \"small_airport\",\"medium_airport\",\"large_airport\"])\n",
    "        \n",
    "        df.reset_index(inplace=True)\n",
    "    \n",
    "        return df\n",
    "\n",
    "## this class is there to prep the freq data\n",
    "\n",
    "class Pandas_freq(object):\n",
    "    def __init__(self,df):\n",
    "        self.df=df\n",
    "        \n",
    "    def indexSet(self,column='airport_ident'):\n",
    "        df = self.df\n",
    "        df.set_index(column,inplace=True)\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def freqselect(self):\n",
    "        df = self.df\n",
    "        df=df['frequency_mhz']\n",
    "        return df\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "class MergingAnF(object):\n",
    "    def __init__(self,airport,data):\n",
    "        self.airport=airport\n",
    "        self.data=data\n",
    "    \n",
    "    def mergeAnF(self):\n",
    "        mergedAnF=pd.merge(self.airport,self.data,left_on='ident',right_on='airport_ident',how='left')\n",
    "        return mergedAnF\n",
    "\n",
    "class Copying_freq(object):\n",
    "    def __init__(self,combined_data):\n",
    "        self.combined_data=combined_data\n",
    "       \n",
    "    def copyfreq(self,airportsize,freqmhz='frequency_mhz'):\n",
    "        self.combined_data[airportsize] = self.combined_data[airportsize].fillna(self.combined_data[freqmhz])\n",
    "    \n",
    "    def returnDataFrame(self):\n",
    "        return self.combined_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79b972a",
   "metadata": {},
   "source": [
    "#### Json backup and Restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2047e743",
   "metadata": {},
   "outputs": [],
   "source": [
    "##This block is used to backup the prepped data in .json format\n",
    "class Js_func(object):\n",
    "    def __init__(self,file=None,filename=None):\n",
    "        self.file=file\n",
    "        self.filename=filename\n",
    "    \n",
    "    def js_backup(self):\n",
    "        name=self.filename\n",
    "        dateTimeObj=datetime.datetime.now()\n",
    "        date = dateTimeObj.strftime(\"%d-%b-%Y (%H%M%S)\")\n",
    "        outFile=open(name+\" \"+date+\".json\",\"w\")\n",
    "        json.dump(self.file,outFile)\n",
    "        outFile.close()\n",
    "        showinfo(\"Saved directory\",os.getcwd())\n",
    "    \n",
    "    def js_restore(self):\n",
    "        preppedColl.delete_many({})\n",
    "        inFile=open(self.file,'r')\n",
    "        dataFile=json.loads(inFile.read())\n",
    "        dataFile_loaded=loads(dataFile)\n",
    "        inFile.close()\n",
    "        return dataFile_loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67799e7f",
   "metadata": {},
   "source": [
    "#### MongoDB\n",
    "this pilot version of the software will require the user to start MongoDB's shell before running the program and connect to a local host -  mongodb://localhost:27017/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8439110f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are default setting for the pilot. Database: aviation, Collection: airports,runway, freq \n",
    "mongo=MongoDB_controls(\"mongodb://localhost:27017/\")\n",
    "\n",
    "# naming the database. Name given aviation\n",
    "aviationDB=mongo.mongo_db(\"aviation\")\n",
    "\n",
    "#creating collections. At the moment this is hardcoded but can be changed for the production version \n",
    "airportColl=mongo.mongo_collection(aviationDB,\"airportColl\")\n",
    "runwayColl=mongo.mongo_collection(aviationDB,\"runwaysColl\")\n",
    "freqColl=mongo.mongo_collection(aviationDB,\"freqColl\")\n",
    "preppedColl=mongo.mongo_collection(aviationDB,\"airFreqColl\")\n",
    "preppedCollincRunway=mongo.mongo_collection(aviationDB,\"airFreqRunColl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf995f4f",
   "metadata": {},
   "source": [
    "#### Adding collections to MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b0f2316",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inserting data into collections\n",
    "def toDB(coll,data):\n",
    "    mongo.mongo_insertMany(coll,data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade0a8c5",
   "metadata": {},
   "source": [
    "#### Core thread where the program comes together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ba4e613",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def airportData(path=\"None\",db=aviationDB,coll=airportColl):\n",
    "    if path != None:\n",
    "            ## the valgate passes a csv to the Validation class to check if the labels found in the csv match the target csv  \n",
    "            ## if there is a match the data is is allowed in \n",
    "        valgate=\"\"\n",
    "        try:\n",
    "            with open(path,'r',encoding='utf-8') as csv_file:\n",
    "                airport = csv.DictReader(csv_file, delimiter=',')\n",
    "                #the following code checks that the incoming csv contains the relevant labels\n",
    "                airportlabels=['id', 'ident', 'type', 'name', 'latitude_deg', 'longitude_deg', 'elevation_ft', \n",
    "                                'continent', 'iso_country', 'iso_region', 'municipality', 'scheduled_service', 'gps_code', \n",
    "                                'iata_code', 'local_code', 'home_link', 'wikipedia_link', 'keywords']\n",
    "                \n",
    "                #this block is making a call to the validation class            \n",
    "                airportval=Validation(airport)\n",
    "                if airportval.validation_check(airportlabels)==True:\n",
    "                    valgate=True\n",
    "                else:\n",
    "                    valgate=False\n",
    "        \n",
    "                if valgate==True:\n",
    "                    try:\n",
    "                        with open(path,'r',encoding='utf-8') as csv_file:\n",
    "                            airport = csv.DictReader(csv_file, delimiter=',')\n",
    "                            airportID=Mongo_prep(airport)\n",
    "                            #### Needs checking but this is the entity relationship structure\n",
    "                            air_ToDB_Prepped=airportID.iD()\n",
    "                            toDB(coll,air_ToDB_Prepped)\n",
    "                            showinfo(\"Imported\",\"Airport data imported\")\n",
    "                        \n",
    "                    #Main purpose is to inform the user that the .csv being imported is already in the database or \n",
    "                    #the .cvs contains id repeats that in the database\n",
    "                    except BulkWriteError as bwe:\n",
    "                        showinfo(\"Error\",\".csv already important/.csv has repeating IDs\")\n",
    "                        return(bwe.details)\n",
    "                    \n",
    "                    ###this error handling block is to caputre all other errors\n",
    "                    except:\n",
    "                        showinfo(\"Error\",\"***Please contact administartor\")\n",
    "                else:\n",
    "                    showinfo(\"Error\",\"Validation checkes failed please check .csv labels\")\n",
    "        except FileNotFoundError:\n",
    "            showinfo(\"Error\",\"No file selected or file not found \")\n",
    "            \n",
    "        ###this error handling block is to caputre all other errors\n",
    "        except:\n",
    "            showinfo(\"Error\", \"***Please contact administartor\")\n",
    "     \n",
    "\n",
    "       \n",
    "                \n",
    "\n",
    "\n",
    "def runwayData(path=\"None\",db=aviationDB,coll=runwayColl):\n",
    "    if path != None:\n",
    "        \n",
    "        valgate=\"\"\n",
    "        try:\n",
    "            with open(path,'r',encoding='utf-8') as csv_file:\n",
    "                runway = csv.DictReader(csv_file, delimiter=',')\n",
    "                #the following code preps airport.csv for MongoDB\n",
    "                \n",
    "                runwayLabels=[\"id\",\"airport_ref\",\"airport_ident\",\"length_ft\",\"width_ft\",\"surface\",\n",
    "                              \"lighted\",\"closed\",\"le_ident\",\"le_latitude_deg\",\"le_longitude_deg\",\"le_elevation_ft\",\n",
    "                              \"le_heading_degT\",\"le_displaced_threshold_ft\",\"he_ident\",\"he_latitude_deg\",\"he_longitude_deg\",\n",
    "                              \"he_elevation_ft\",\"he_heading_degT\",\"he_displaced_threshold_ft\"]\n",
    "                \n",
    "                #this block is making a call to the validation class    \n",
    "                runval=Validation(runway)\n",
    "                if runval.validation_check(runwayLabels)==True:\n",
    "                    valgate=True\n",
    "                else:\n",
    "                    valgate=False\n",
    "                    print(\"Fail\")\n",
    "                \n",
    "                \n",
    "                #if the validation check passes the following code is run\n",
    "                if valgate==True:\n",
    "                    try:\n",
    "                        with open(path,'r',encoding='utf-8') as csv_file:\n",
    "                            runway = csv.DictReader(csv_file, delimiter=',')\n",
    "                            runID=Mongo_prep(runway)\n",
    "                            runway_ToDB_Prepped=runID.iD()\n",
    "                            toDB(coll,runway_ToDB_Prepped)\n",
    "                            showinfo(\"Imported\",\"Runway data imported\")\n",
    "                        \n",
    "                    #Main purpose is to inform the user that the .csv being imported is already in the database or \n",
    "                    #the .cvs contains id repeats that in the database\n",
    "                    except BulkWriteError as bwe:\n",
    "                        showinfo(\"Error\",\".csv already important/.csv has repeating IDs\")\n",
    "                        return(bwe.details)\n",
    "                    \n",
    "                else:\n",
    "                    showinfo(\"Error\",\"Validation checkes failed please check .csv labels\")\n",
    "                    \n",
    "        except FileNotFoundError:\n",
    "            showinfo(\"Error\",\"No file selected or file not found \")\n",
    "            \n",
    "        ###this error handling block is to caputre all other errors\n",
    "        except:\n",
    "            showinfo(\"Error\",\"Please contact administartor\")\n",
    "          \n",
    "            \n",
    "\n",
    "def freqData(path=\"None\",db=aviationDB,coll=freqColl):\n",
    "    if path != None:\n",
    "        \n",
    "        valgate=\"\"\n",
    "        try:\n",
    "            with open(path,'r',encoding='utf-8') as csv_file:\n",
    "                freq = csv.DictReader(csv_file, delimiter=',')\n",
    "            \n",
    "                #the following code checks the incoming csv contains the relevant labels\n",
    "                airfreqlabels=['id','airport_ref','airport_ident','type','description','frequency_mhz']\n",
    "                \n",
    "                \n",
    "                #this block is making a call to the validation class    \n",
    "                freqval=Validation(freq)\n",
    "                if freqval.validation_check(airfreqlabels)==True:\n",
    "                    valgate=True\n",
    "                else:\n",
    "                    valgate=False\n",
    "                    \n",
    "                    \n",
    "                #if the validation check passes the following code is run\n",
    "                if valgate ==True:\n",
    "                    try:\n",
    "                        with open(path,'r',encoding='utf-8') as csv_file:\n",
    "                            freq = csv.DictReader(csv_file, delimiter=',')\n",
    "                \n",
    "                            #the following code preps airport-frequencies.csv for MongoDB\n",
    "                            airport_freq=Mongo_prep(freq)\n",
    "                            freq_ToDB_Prepped=airport_freq.iD()\n",
    "                            toDB(coll,freq_ToDB_Prepped)\n",
    "                            showinfo(\"Imported\",\"Frequency data imported\")\n",
    "                            \n",
    "                    except BulkWriteError as bwe:\n",
    "                        showinfo(\"Error\",\".csv already important/.csv has repeating IDs\")\n",
    "                        return(bwe.details)\n",
    "                else:\n",
    "                    showinfo(\"Error\",\"Validation checkes failed please check .csv labels\")\n",
    "                    \n",
    "        except FileNotFoundError:\n",
    "            showinfo(\"Error\",\"No file selected or file not found \")\n",
    "            \n",
    "        ###this error handling block is to caputre all other errors\n",
    "        except:\n",
    "            showinfo(\"Error\",\"Please contact administartor\")\n",
    "            \n",
    "def cleaningNmerging(airportcoll=airportColl,freqcoll=freqColl,db=aviationDB,coll=preppedColl):\n",
    "    \n",
    "    airportdata=Pandas_airport(pd.DataFrame(list(airportColl.find({}))))\n",
    "    \n",
    "    airportdata.dropTypeClose()\n",
    "    airportdata.airportTypeColumns()\n",
    "    airportdata.marker('small_airport')\n",
    "    airportdata.marker('heliport')\n",
    "    airportdata.marker('seaplane_base')\n",
    "    airportdata.marker('balloonport')\n",
    "    airportdata.marker('medium_airport')\n",
    "    airportdata.marker('large_airport')\n",
    "    \n",
    "    \n",
    "    airportdata=airportdata.sizeNGB_sec()\n",
    "    airportdata.drop(columns=[\"index\"],inplace=True)\n",
    "    \n",
    "    freqdata=Pandas_freq(pd.DataFrame(list(freqcoll.find({}))))\n",
    "    removingDuplicates=freqdata.indexSet()\n",
    "    removingDuplicates['duplicates']=removingDuplicates.index+removingDuplicates['frequency_mhz']\n",
    "    removingDuplicates.drop_duplicates(subset=['duplicates'],inplace=True)\n",
    "    #here the index and  the frequency column are selected for mereging\n",
    "    freqselect=removingDuplicates['frequency_mhz']\n",
    " \n",
    "    \n",
    "    toMerged=MergingAnF(airportdata,freqselect)\n",
    "    mergedData=Copying_freq(toMerged.mergeAnF())\n",
    "    mergedData.copyfreq('small_airport')\n",
    "    mergedData.copyfreq('medium_airport')\n",
    "    mergedData.copyfreq('large_airport')\n",
    "\n",
    "\n",
    "    surrogateKey=Mongo_prep()\n",
    "    mergedDBtoDB=surrogateKey.surrogateKey(mergedData.returnDataFrame())\n",
    "               \n",
    " \n",
    "    try:\n",
    "        preppedColl.delete_many({})\n",
    "        toDB(coll,mergedDBtoDB.to_dict('records'))\n",
    "        showinfo(\"Executed\",\"Data prepared\")\n",
    "    except:\n",
    "        showinfo(\"Error\",\"Please contact administartor\")\n",
    "\n",
    "def cleaningNmergingRunway(runwayColl=runwayColl,db=aviationDB):\n",
    "    freq_airport=pd.DataFrame(list(preppedColl.find({})))\n",
    "    runsize=pd.DataFrame(list(runwayColl.find({})))\n",
    "    \n",
    "    runsize[\"unique?\"]=(runsize[\"airport_ident\"])+(runsize[\"le_ident\"])\n",
    "    runsize.drop_duplicates(subset=[\"unique?\"],inplace=True)\n",
    "    runsize=runsize.filter(['airport_ident','length_ft','width_ft','unique?'])\n",
    "   \n",
    "    toMerged=MergingAnF(freq_airport,runsize)\n",
    "    runway=toMerged.mergeAnF()\n",
    "   \n",
    "    runway.drop_duplicates(subset=[\"unique?\"],inplace=True)\n",
    "    runway.drop(runway.index[runway['type']=='heliport'],inplace=True)\n",
    "\n",
    "    runway['width_ft'].replace('', np.nan, inplace=True)\n",
    "    runway['length_ft'].replace('', np.nan, inplace=True)\n",
    "    runway.dropna(subset=[\"length_ft\"],inplace=True)\n",
    "    runway.dropna(subset=[\"width_ft\"],inplace=True)\n",
    "    runway=runway.astype({'length_ft':\"float\"})\n",
    "    runway=runway.astype({'width_ft':\"float\"})\n",
    "    runway['area']=runway['length_ft']*runway['width_ft']\n",
    "    runway_totalArea=runway[['ident','unique?','area']]\n",
    "    runway.drop(columns=['area'],inplace=True)\n",
    "    test2=runway_totalArea.groupby('ident').sum()\n",
    "    runway=pd.merge(runway,test2,left_on='ident',right_on='ident',how='left')\n",
    "    \n",
    "    runway.rename(columns={'_id':'Foreign_ID_AirportFreq'},inplace=True)\n",
    "    runway.rename(columns={'unique?':'_id'},inplace=True)\n",
    "    \n",
    "\n",
    "    try:\n",
    "        preppedCollincRunway.delete_many({})\n",
    "        toDB(preppedCollincRunway,runway.to_dict('records'))\n",
    "        showinfo(\"Executed\",\"Data prepared\")\n",
    "    except:\n",
    "        pass\n",
    "        showinfo(\"Error\",\"Please contact administartor\")\n",
    "    \n",
    "    \n",
    "    \n",
    "##This block is used to backup the prepped in .json format\n",
    "\n",
    "def backup_coll():\n",
    "    prepped=preppedColl.find({})\n",
    "    save_prepped=dumps(prepped)\n",
    "    save=Js_func(file=save_prepped,filename=\"GBAirpotFreq\")\n",
    "    save.js_backup()\n",
    "\n",
    "def restore_coll(path=None):\n",
    "    try:\n",
    "        restore_file=Js_func(file=path,filename=None)\n",
    "        file=restore_file.js_restore()\n",
    "        toDB(preppedColl,restore_file.js_restore())\n",
    "        showinfo(\"Restored\",\"Collection restored\")\n",
    "    except FileNotFoundError:\n",
    "        showinfo(\"Error\",\"No file selected or file not found \")\n",
    "\n",
    "##Q3ai of the brief \n",
    "def largeMMM(df):\n",
    "    centralT=df[['ident','large_airport']]\n",
    "    centralT=centralT['large_airport'].replace('', np.nan)\n",
    "    centralT=centralT.dropna()\n",
    "    typechange=centralT.astype({'large_airport':\"float\"})\n",
    "    centralTendacy=[]\n",
    "    centralTendacy.append(typechange.mean())\n",
    "    centralTendacy.append(typechange.mode())\n",
    "    centralTendacy.append(typechange.median())\n",
    "    return centralTendacy\n",
    "\n",
    "##Q3aii of the brief \n",
    "def freqmoreHundred(df):\n",
    "    df.dropna(subset = ['frequency_mhz'], inplace=True)\n",
    "    dffloat=df.astype({'frequency_mhz':\"float\"})\n",
    "    dffloat.drop(dffloat.index[dffloat['frequency_mhz'] <=100], inplace=True)\n",
    "    dffloat=dffloat.filter(['frequency_mhz'])\n",
    "    centralTendacy= pd.DataFrame()\n",
    "    centralTendacy['Mean'] = np.around(dffloat.mean(), decimals=2)\n",
    "    centralTendacy['Median'] = np.around(dffloat.median(), decimals=2)\n",
    "    centralTendacy['Mode'] =np.around( dffloat.iloc[0], decimals=2)\n",
    "    return centralTendacy\n",
    "\n",
    "##Q4\n",
    "def smallairgraph(df):\n",
    "    df['small_airport'].replace('', np.nan, inplace=True)\n",
    "    df.dropna(subset = ['small_airport'], inplace=True)\n",
    "    grouping=df.astype({'small_airport':\"float\"})\n",
    "    grouping['quartiles']=pd.cut(grouping['small_airport'],50)\n",
    "    grouped=grouping.groupby('quartiles').count()\n",
    "    grouped.reset_index(inplace=True)\n",
    "    grouped=grouped[['quartiles','small_airport']]\n",
    "    grouped=grouped.astype({'quartiles':\"string\"})\n",
    "    return grouped\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7e0a0c",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e675a67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_smallairport():\n",
    "    \n",
    "    window.geometry(\"1000x800\")\n",
    "    grapFrame=Frame(window)\n",
    "    \n",
    "    df=smallairgraph(pd.DataFrame(list(preppedColl.find({}))))\n",
    "    graph=plt.figure()\n",
    "    small_airportdist=sns.barplot(x=df['quartiles'],y=df['small_airport'],color='black')\n",
    "    small_airportdist.set(xlabel='Ranges',ylabel='Frequency',title='Small Airport Com Freq')\n",
    "    txt=\"The above graph shows the communications frequencies used by samll airports.\\n The frequencies are grouped into ranges for ease of display\"\n",
    "    plt.figtext(0.5, 0.2, txt, wrap=True, horizontalalignment='center', fontsize=12)\n",
    "    plt.xticks(rotation=70)\n",
    "    plt.tight_layout()\n",
    "        \n",
    "    canvas=FigureCanvasTkAgg(graph,master=grapFrame)\n",
    "    canvas.draw()\n",
    "    canvas.get_tk_widget().place(x=100,y=20,width=800,height=700)\n",
    "    \n",
    "    Button(grapFrame,text=\"<< Back\",bg='yellow',command=lambda:[stats(),grapFrame.destroy()]).place(x=50,y=700,width=120,height=50)\n",
    "    \n",
    "    grapFrame.place(x=10,y=20,width=900,height=800)\n",
    "    \n",
    "    \n",
    "def sizeVsFreq():\n",
    "    window.geometry(\"900x900\")\n",
    "    grapFrame=Frame(window)\n",
    "    \n",
    "    df=pd.DataFrame(list(preppedCollincRunway.find({})))\n",
    "    toplot=df[['area','frequency_mhz']]\n",
    "    toplot=toplot.fillna(0)\n",
    "    toplot=toplot.astype({'frequency_mhz':\"float\"})\n",
    "    corrval=toplot.corr()\n",
    "    \n",
    "    graph=plt.figure(figsize = (15,15))\n",
    "    freqregplot=sns.regplot(x='area',y='frequency_mhz',data=toplot,)\n",
    "    freqregplot.set(xlabel='Airport size',ylabel='Frequency in mhz size',title='Small Airport Com Freq')\n",
    "    txt=\"The above graph shows the communications frequencies used by samll airports.\\n The frequencies are grouped into ranges for easy of display\\n Correlation Coefficient: {:.3f}\".format(corrval[\"frequency_mhz\"][0])\n",
    "    plt.figtext(0.5, 0.01, txt, wrap=True, horizontalalignment='center', fontsize=12)\n",
    "    \n",
    "    canvas=FigureCanvasTkAgg(graph,master=grapFrame)\n",
    "    canvas.draw()\n",
    "    canvas.get_tk_widget().place(x=100,y=20,width=700,height=700)\n",
    "    \n",
    "    Button(grapFrame,text=\"<< Back\",bg='yellow',command=lambda:[stats(),grapFrame.destroy()]).place(x=50,y=745,width=120,height=50)\n",
    "    \n",
    "    grapFrame.place(x=10,y=20,width=1000,height=1000)\n",
    "    \n",
    "def allairports_MMM():\n",
    "    window.geometry(\"400x250\")\n",
    "    grapFrame=Frame(window)\n",
    "    \n",
    "    meanText=Text(grapFrame, height = 2, width = 10,font=15)\n",
    "    medianText=Text(grapFrame, height = 2, width = 10,font=15)\n",
    "    modeText=Text(grapFrame, height = 2, width = 10,font=15)\n",
    "    \n",
    "    description=Label(grapFrame,text=\"The following data shows the central \\ntendency of all available Frequencies\")\n",
    "    description.config(font=15)\n",
    "    meanlabel=Label(grapFrame,text=\"Mean\")\n",
    "    meanlabel.config(font=15)\n",
    "    medianlabel=Label(grapFrame,text=\"Median\")\n",
    "    medianlabel.config(font=15)\n",
    "    modelabel=Label(grapFrame,text=\"Mode\")\n",
    "    modelabel.config(font=15)\n",
    "\n",
    "    \n",
    "    mmm=freqmoreHundred(pd.DataFrame(list(preppedColl.find({}))))\n",
    "    \n",
    "    mean=mmm['Mean'][0]\n",
    "    median=mmm['Median'][0]\n",
    "    mode=mmm['Mode'][0]\n",
    "    \n",
    "    \n",
    "    description.pack()\n",
    "    meanlabel.pack() \n",
    "    meanText.pack()\n",
    "    medianlabel.pack() \n",
    "    medianText.pack()\n",
    "    modelabel.pack() \n",
    "    modeText.pack()\n",
    "    \n",
    "    meanText.insert('end',mean)\n",
    "    meanText.config(state='disabled')\n",
    "    medianText.insert('end',median)\n",
    "    medianText.config(state='disabled')\n",
    "    modeText.insert('end',mode)\n",
    "    modeText.config(state='disabled')\n",
    "    \n",
    "    description.place(x=5,y=100)\n",
    "    meanlabel.place(x=20,y=20)\n",
    "    meanText.place(x=10,y=50)\n",
    "    medianlabel.place(x=140,y=20)\n",
    "    medianText.place(x=120,y=50)\n",
    "    modelabel.place(x=260,y=20)\n",
    "    modeText.place(x=240,y=50)\n",
    "    \n",
    "    Button(grapFrame,text=\"<< Back\",bg='yellow',command=lambda:[stats(),grapFrame.destroy()]).place(x=100,y=170,width=120,height=50)\n",
    "    \n",
    "    grapFrame.place(x=10,y=20,width=1000,height=1000)\n",
    "\n",
    "def largeairports_MMM():\n",
    "    window.geometry(\"400x250\")\n",
    "    grapFrame=Frame(window)\n",
    "    \n",
    "    meanText=Text(grapFrame, height = 2, width = 10,font=15)\n",
    "    medianText=Text(grapFrame, height = 2, width = 10,font=15)\n",
    "    modeText=Text(grapFrame, height = 2, width = 10,font=15)\n",
    "    \n",
    "    description=Label(grapFrame,text=\"The following data shows the central \\ntendency of all Large airports\")\n",
    "    description.config(font=15)\n",
    "    meanlabel=Label(grapFrame,text=\"Mean\")\n",
    "    meanlabel.config(font=15)\n",
    "    medianlabel=Label(grapFrame,text=\"Median\")\n",
    "    medianlabel.config(font=15)\n",
    "    modelabel=Label(grapFrame,text=\"Mode\")\n",
    "    modelabel.config(font=15)\n",
    "   \n",
    "    mmm=largeMMM(pd.DataFrame(list(preppedColl.find({}))))\n",
    "    \n",
    "    mean=np.round(mmm[0],decimals=2)\n",
    "    median=np.round(mmm[2],decimals=2)\n",
    "    mode=np.round(mmm[1][0],decimals=2)\n",
    "    \n",
    "    \n",
    "    description.pack()\n",
    "    meanlabel.pack() \n",
    "    meanText.pack()\n",
    "    medianlabel.pack() \n",
    "    medianText.pack()\n",
    "    modelabel.pack() \n",
    "    modeText.pack()\n",
    "    \n",
    "    meanText.insert('end',mean)\n",
    "    meanText.config(state='disabled')\n",
    "    medianText.insert('end',median)\n",
    "    medianText.config(state='disabled')\n",
    "    modeText.insert('end',mode)\n",
    "    modeText.config(state='disabled')\n",
    "    \n",
    "    description.place(x=5,y=100)\n",
    "    meanlabel.place(x=20,y=20)\n",
    "    meanText.place(x=10,y=50)\n",
    "    medianlabel.place(x=140,y=20)\n",
    "    medianText.place(x=120,y=50)\n",
    "    modelabel.place(x=260,y=20)\n",
    "    modeText.place(x=240,y=50)\n",
    "    \n",
    "    Button(grapFrame,text=\"<< Back\",bg='yellow',command=lambda:[stats(),grapFrame.destroy()]).place(x=100,y=170,width=120,height=50)\n",
    "    \n",
    "    grapFrame.place(x=10,y=20,width=1000,height=1000)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80f01a7",
   "metadata": {},
   "source": [
    "### tkinter process for the visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15839bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats():\n",
    "    \n",
    "    window.geometry(\"300x300\")\n",
    "    grapMFrame=Frame(window)\n",
    "        \n",
    "    \n",
    "    Button(grapMFrame,text=\"Small Airport Com frequencies\",command=lambda : [freq_smallairport(),grapMFrame.destroy()]).grid(row=1,column=1,sticky='NESW', pady=7,padx=2)\n",
    "    Button(grapMFrame,text=\"Size of Airport Vs Com frequencies\",command=lambda : [sizeVsFreq(),grapMFrame.destroy()]).grid(row=2,column=1,sticky='NESW', pady=7,padx=2)\n",
    "    Button(grapMFrame,text=\"All Freqs Mean,Median & Mode \",command=lambda : [allairports_MMM(),grapMFrame.destroy()]).grid(row=3,column=1,sticky='NESW', pady=7,padx=2)\n",
    "    Button(grapMFrame,text=\"Large Airport Freqs Mean,Median & Mode \",command=lambda : [largeairports_MMM(),grapMFrame.destroy()]).grid(row=4,column=1,sticky='NESW', pady=7,padx=2)\n",
    "    \n",
    "    mmButton(grapMFrame,grapMFrame).grid(row=5,column=1,sticky='NESW', pady=7,padx=2)\n",
    "    \n",
    "    grapMFrame.place(x=10,y=20,width=1000,height=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdb70dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def browseFiles_csv():\n",
    "        filetypes = (\n",
    "        ('csv files', '*.csv'),\n",
    "        ('All files', '*.*'))\n",
    "        filename = fd.askopenfilename(title='Open a file', initialdir=os.getcwd() ,filetypes=filetypes)\n",
    "        if filename == None:\n",
    "            return \"None\"\n",
    "        else:\n",
    "            return filename\n",
    "        \n",
    "def browseFiles_json():\n",
    "        filetypes = (\n",
    "        ('json files', '*.json'),\n",
    "        ('All files', '*.*'))\n",
    "        filename = fd.askopenfilename(title='Open a file', initialdir=os.getcwd(),filetypes=filetypes)\n",
    "        if filename == None:\n",
    "            return \"None\"\n",
    "        else:\n",
    "            return filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b0b5e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data():\n",
    "    \n",
    "    window.title(\"Mongo Import\")\n",
    "    window.geometry(\"400x250\")\n",
    "    importDataWindow=Frame(window)\n",
    "    \n",
    "    aiportimport=StringVar()\n",
    "    aiportimport.set(\"Please click to select location of airport data: \")\n",
    "    freqimport=StringVar()\n",
    "    freqimport.set(\"Please click to select location of frequency data: \")\n",
    "    runimport=StringVar()\n",
    "    runimport.set(\"Please click to select location of runway data: \")\n",
    "    \n",
    "    Label(importDataWindow,text=aiportimport.get()).grid(row=1,column=1,sticky='W', pady=7,padx=2)\n",
    "    Label(importDataWindow,text=freqimport.get()).grid(row=2,column=1,sticky='W', pady=7,padx=2)\n",
    "    Label(importDataWindow,text=runimport.get()).grid(row=3,column=1,sticky='W', pady=7)\n",
    "    \n",
    "    #https://www.geeksforgeeks.org/file-explorer-in-python-using-tkinter/\n",
    "    #https://www.pythontutorial.net/tkinter/tkinter-open-file-dialog/\n",
    "    airport_import=Button(importDataWindow,text=\"Import\",command=lambda:[airportData(browseFiles_csv())]).grid(row=1,column=2,sticky='W', pady=7,padx=2)\n",
    "    freq_import=Button(importDataWindow,text=\"Import\",command=lambda:[freqData(browseFiles_csv())]).grid(row=2,column=2,sticky='W', pady=7,padx=2)\n",
    "    runway_import=Button(importDataWindow,text=\"Import\",command=lambda:[runwayData(browseFiles_csv())]).grid(row=3,column=2,sticky='W', pady=7,padx=2)                                                                    \n",
    "    \n",
    "    \n",
    "    mmButton(importDataWindow,importDataWindow).grid(row=5,column=1,sticky='NESW', pady=7,padx=2)\n",
    "    \n",
    "    \n",
    "    importDataWindow.place(x=10,y=20,width=400,height=560)\n",
    "                                                       \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7878a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def restoreTK():\n",
    "    window.title(\"Mongo Restore\")\n",
    "    window.geometry(\"400x200\")\n",
    "    restoreWindow=Frame(window)\n",
    "    \n",
    "    messagebox.showwarning(\"Waring!!\",\"All data is will be deleted Prepped collection. To carry on click execute\")\n",
    "    \n",
    "    restoremessage=StringVar()\n",
    "    restoremessage.set(\"Please select the location of the Prepped data you would like to restore: \")\n",
    "\n",
    "    \n",
    "    restoreL=Label(restoreWindow,text=restoremessage.get()).grid(row=1,column=1,sticky='NESW', pady=7,padx=2)\n",
    "    Button(restoreWindow,text=\"Restore\",command=lambda:[restore_coll(browseFiles_json())]).grid(row=2,column=1,sticky='NESW')\n",
    "    \n",
    "    Button(restoreWindow,text=\"<< Back\",bg='yellow',command=lambda:[prepped_data(),restoreWindow.destroy()]).place(x=150,y=70,width=120,height=50)\n",
    "    \n",
    "    restoreWindow.place(x=10,y=20,width=400,height=560)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f677bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepped_data():\n",
    "    window.title(\"Mongo Data Prep\")\n",
    "    window.geometry(\"300x300\")\n",
    "    backupPrepWindow=Frame(window)\n",
    "    \n",
    "    Button(backupPrepWindow,text=\"Prep Freq and Airprot Data\",command=lambda:[cleaningNmerging()]).grid(row=1,column=1,sticky='NESW', pady=7,padx=2)\n",
    "    Button(backupPrepWindow,text=\"Prep runway\",command=lambda:[cleaningNmergingRunway()]).grid(row=2,column=1,sticky='NESW', pady=7,padx=2)\n",
    "    Button(backupPrepWindow,text=\"Backup prepped Data\",command=lambda:[backup_coll()]).grid(row=3,column=1,sticky='NESW', pady=7,padx=2)\n",
    "    Button(backupPrepWindow,text=\"Restore prepped Data\",command=lambda:[restoreTK(),backupPrepWindow.destroy()]).grid(row=4,column=1,sticky='NESW', pady=7,padx=2)\n",
    "    \n",
    "    \n",
    "    ##button to go back to the main menu\n",
    "    mmButton(backupPrepWindow,backupPrepWindow).grid(row=5,column=1,sticky='NESW', pady=7,padx=2)\n",
    "    \n",
    "    \n",
    "    backupPrepWindow.place(x=10,y=20,width=400,height=560)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d10ddcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mmButton(x=None,frame=None):\n",
    "    mainMenuButton=Button(x,text=\"<< Main Menu\",bg='yellow',command=lambda:[main_Menu(),frame.destroy()])\n",
    "    return mainMenuButton\n",
    "\n",
    "\n",
    "def main_Menu():\n",
    "    window.geometry(\"300x300\")\n",
    "    mainMenu=Frame(window)\n",
    "    \n",
    "    Button(mainMenu,text=\"Data import\",command=lambda:[import_data(),mainMenu.destroy()]).grid(row=1,column=1,sticky='NESW', pady=7,padx=2)\n",
    "    Button(mainMenu,text=\"Data prep\",command=lambda:[prepped_data(),mainMenu.destroy()]).grid(row=2,column=1,sticky='NESW', pady=7,padx=2)\n",
    "    Button(mainMenu,text=\"Descriptive Stats\",command=lambda:[stats(),mainMenu.destroy()]).grid(row=3,column=1,sticky='NESW', pady=7,padx=2)\n",
    "    Button(mainMenu,text=\"Quit\",command=lambda:[window.destroy()],bg='red').grid(row=5,column=1,sticky='NESW', pady=7,padx=2)\n",
    "    \n",
    "    \n",
    "    mainMenu.place(x=10,y=20,width=150,height=560)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb61a7bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "window =Tk()\n",
    "window.title(\"Main Menu\")\n",
    "window.geometry(\"\")\n",
    "\n",
    "main_Menu()\n",
    "\n",
    "\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e65e10a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
